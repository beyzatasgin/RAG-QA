# Langflow ile RAG TabanlÄ± Restoran S&C UygulamasÄ±

Langflow kullanÄ±larak kurulmuÅŸ **Retrieval-Augmented Generation (RAG)** tabanlÄ± bir soru-cevap uygulamasÄ±. PDF dokÃ¼manÄ±na dayalÄ±, kod yazmadan gÃ¶rsel nodeâ€™larla oluÅŸturulmuÅŸ chatbot.

---

## ğŸ“‹ Ä°Ã§indekiler

- [Genel BakÄ±ÅŸ](#genel-bakÄ±ÅŸ)
- [Proje YapÄ±sÄ± (AkÄ±ÅŸ AdÄ±mlarÄ±)](#proje-yapÄ±sÄ±-akÄ±ÅŸ-adÄ±mlarÄ±)
- [Ä°ÅŸ AkÄ±ÅŸÄ± (Flow) AÃ§Ä±klamasÄ±](#iÅŸ-akÄ±ÅŸÄ±-flow-aÃ§Ä±klamasÄ±)
- [Kurulum](#kurulum)
- [KullanÄ±m](#kullanÄ±m)
- [GitHub NotlarÄ±](#github-notlarÄ±)

---

## Genel BakÄ±ÅŸ

Uygulama ÅŸu senaryoyu hedefler:

- **Restoran Q&A PDF** gibi bir dokÃ¼mandaki sÄ±k sorulan sorulara (Ã§alÄ±ÅŸma saatleri, konum, Ã¶deme seÃ§enekleri, menÃ¼ vb.) otomatik cevap vermek.
- KullanÄ±cÄ± adÄ±na gÃ¶re **konuÅŸma geÃ§miÅŸini (message history)** saklamak; farklÄ± kullanÄ±cÄ±lar kendi geÃ§miÅŸlerini gÃ¶rÃ¼r.
- **Vector store** (Astra DB) ile dokÃ¼mandan anlamsal arama yapÄ±p, LLM'e sadece ilgili baÄŸlamÄ± vererek doÄŸru ve gÃ¼ncel cevaplar Ã¼retmek.

TÃ¼m bu akÄ±ÅŸ Langflowâ€™da **gÃ¶rsel nodeâ€™lar** ile baÄŸlanarak oluÅŸturulur; kod yazÄ±lmaz.

---

## Proje YapÄ±sÄ± (AkÄ±ÅŸ AdÄ±mlarÄ±)

### 1. Kurulum ve Langflowâ€™u Ã‡alÄ±ÅŸtÄ±rma

- **Python 3.10+** gereklidir.
- Langflow prerelease kurulumu:
  - Windows: `pip install langflow --pre --force-reinstall`
  - Mac/Linux: `pip3 install langflow --pre --force-reinstall`
- Ã‡alÄ±ÅŸtÄ±rma: `langflow run` â†’ TarayÄ±cÄ±da `localhost` Ã¼zerinden arayÃ¼z aÃ§Ä±lÄ±r.
- Yeni proje: **New Project** â†’ **Blank Flow** seÃ§ilir. AkÄ±ÅŸlar JSON olarak saklanÄ±r; import/export mÃ¼mkÃ¼ndÃ¼r.

### 2. PDF ve Temel Girdiler

- KullanÄ±lacak **PDF** (Ã¶rneÄŸin restoran S&C) proje klasÃ¶rÃ¼nde veya Langflowâ€™da eriÅŸilebilir bir yerde tutulur (Ã¶rn. `Resturaunt Q&A.pdf`).
- **Inputs** kÄ±smÄ±ndan:
  - **Text Input** â†’ KullanÄ±cÄ± adÄ± (Name) iÃ§in.
  - **Chat Input** â†’ KullanÄ±cÄ±nÄ±n soracaÄŸÄ± soru iÃ§in.
  - **Prompt** (Prompt Template) â†’ LLMâ€™e gidecek metni ÅŸablonla oluÅŸturmak iÃ§in eklenir.

### 3. Prompt Åablonu ve DeÄŸiÅŸkenler

Prompt Templateâ€™te kullanÄ±lan ÅŸablon Ã¶rneÄŸi:

```
Hey, answer the users question based on
the following context.
The context in this {context}
And this is the message history: {history}
```

- **DeÄŸiÅŸkenler:** `{context}`, `{history}`, `{question}` (veya `question` alanÄ±).
- **context** â†’ Vector storeâ€™dan gelen ilgili metin (RAG sonucu).
- **history** â†’ Message Historyâ€™den gelen konuÅŸma geÃ§miÅŸi.
- **question** â†’ Chat Inputâ€™tan gelen kullanÄ±cÄ± sorusu.

Bu Ã¼Ã§Ã¼ Prompt Templateâ€™e baÄŸlanÄ±r.

### 4. Mesaj GeÃ§miÅŸi (Message History)

- **Message History** (veya Chat Memory) komponenti eklenir.
- **Session ID** olarak **Name** (Text Input) verilir. KullanÄ±cÄ± adÄ± deÄŸiÅŸtikÃ§e farklÄ± oturumlar oluÅŸur; her kullanÄ±cÄ± kendi mesaj geÃ§miÅŸini gÃ¶rÃ¼r.
- **Message** â†’ Chat Inputâ€™tan gelen mesaj.
- **Stored Messages** Ã§Ä±ktÄ±sÄ± Prompt Templateâ€™teki **history** alanÄ±na baÄŸlanÄ±r.
- BÃ¶ylece LLM hem baÄŸlam hem de son birkaÃ§ mesajÄ± gÃ¶rerek cevap verir.

### 5. OpenAI Entegrasyonu

- **Models** bÃ¶lÃ¼mÃ¼nden **OpenAI** seÃ§ilir.
- [OpenAI API Keys](https://platform.openai.com/api-keys) sayfasÄ±ndan **API Key** oluÅŸturulur. (HesabÄ±n fonlanmÄ±ÅŸ olmasÄ± gerekebilir.)
- Langflowâ€™da bu anahtar **Credential** tipinde bir deÄŸiÅŸkene (Ã¶rn. `OPENAI_API_Key`) atanÄ±r; gÃ¼venli saklama iÃ§in credential kullanÄ±lÄ±r.
- Prompt Templateâ€™in Ã§Ä±ktÄ±sÄ± **OpenAI** nodeâ€™unun **Input**â€™una baÄŸlanÄ±r.
- **Chat Output** eklenir; OpenAIâ€™nin **Model Response** Ã§Ä±ktÄ±sÄ± Chat Outputâ€™a verilir, **Sender Name** "AI" yapÄ±lÄ±r.

Bu aÅŸamada RAG olmadan basit bir chatbot Ã§alÄ±ÅŸÄ±r; â€œRunâ€ ile test edilir.

### 6. Vector Store (Astra DB) Kurulumu

- **DataStax Astra DB** kullanÄ±lÄ±r (Ã¼cretsiz tier mevcut).
- [Astra DB](https://dtsx.io/3vZk6n2) Ã¼zerinden hesap aÃ§Ä±lÄ±r, **Create Database** â†’ **Serverless Vector** seÃ§ilir.
- Database adÄ± (Ã¶rn. `langflow_tutorial`), provider ve bÃ¶lge seÃ§ilir. OluÅŸturulduktan sonra:
  - **Token** (Application Token)
  - **API Endpoint** (URL)
  - **Collection** adÄ±  
  alÄ±nÄ±r. Bunlar Langflowâ€™da deÄŸiÅŸken olarak (credential/generic) tanÄ±mlanÄ±r.

### 7. DokÃ¼man Ä°ÅŸleme ve VeritabanÄ±na YÃ¼kleme

- **Read File** (veya Generic File Loader): PDF seÃ§ilir (Ã¶rn. `Resturaunt Q&A.pdf`).
- **Split Text**: 
  - **Chunk Size**: 1000 (karakter)
  - **Chunk Overlap**: 200
  - BÃ¶ylece metin kÃ¼Ã§Ã¼k parÃ§alara bÃ¶lÃ¼nÃ¼r; overlap baÄŸlam kaybÄ±nÄ± azaltÄ±r.
- **OpenAI Embeddings**:
  - Model: `text-embedding-3-small`
  - AynÄ± OpenAI API Key kullanÄ±lÄ±r.
- **Astra DB** nodeâ€™u:
  - Token, Endpoint, Database, Collection baÄŸlanÄ±r.
  - **Ingest Data** â†’ Split Textâ€™in **Chunks** Ã§Ä±ktÄ±sÄ±.
  - **Embedding Model** â†’ OpenAI Embeddingsâ€™in Ã§Ä±ktÄ±sÄ±.
  Bu sayede PDF chunkâ€™larÄ± vektÃ¶rlenip Astra DBâ€™de saklanÄ±r. (Ä°lk Ã§alÄ±ÅŸtÄ±rmada vector store oluÅŸturulur.)

### 8. RAG: Arama ve Promptâ€™a BaÄŸlama

- **Chat Input** (kullanÄ±cÄ± sorusu), **Astra DB** nodeâ€™undaki **Search Query** (veya ilgili arama giriÅŸi) alanÄ±na baÄŸlanÄ±r.
- Astra DB, bu sorguyu aynÄ± **OpenAI Embeddings** ile vektÃ¶rleyip veritabanÄ±nda benzerlik aramasÄ± yapar; sonuÃ§lar **Search Results** olarak dÃ¶ner.
- **Parser** (Stringify modunda): Search Resultsâ€™Ä± metne Ã§evirir â†’ bu Ã§Ä±ktÄ± Prompt Templateâ€™teki **context** alanÄ±na verilir.
- ArtÄ±k her kullanÄ±cÄ± sorusunda:
  1. Soru Astra DBâ€™de aranÄ±r.
  2. Ä°lgili parÃ§alar `context` olarak alÄ±nÄ±r.
  3. `context`, `history` ve `question` Prompt Templateâ€™te birleÅŸtirilir.
  4. OpenAI cevap Ã¼retir; Chat Outputâ€™ta gÃ¶sterilir.

### 9. Test ve Ek Notlar

- **Ä°lk soru** bazen anlamsÄ±z cevap verebilir; vector store ilk kez doldurulurken gecikme olabilir. Ä°kinci sorudan itibaren RAG dÃ¼zgÃ¼n Ã§alÄ±ÅŸÄ±r.
- **Ä°sim deÄŸiÅŸtirme**: Name alanÄ± deÄŸiÅŸtirilince Session ID deÄŸiÅŸir; mesaj geÃ§miÅŸi o kullanÄ±cÄ±ya Ã¶zel olur.
- **Export**: AkÄ±ÅŸ **Export** ile JSON olarak indirilebilir; baÅŸka bir Langflow kurulumuna **Import** edilebilir.

---

## Ä°ÅŸ AkÄ±ÅŸÄ± (Flow) AÃ§Ä±klamasÄ±

AkÄ±ÅŸtaki nodeâ€™larÄ±n Ã¶zeti:

| BÃ¶lÃ¼m | Node'lar | AÃ§Ä±klama |
|--------|----------|----------|
| **DokÃ¼man giriÅŸi** | Read File â†’ Split Text | PDF okunur, 1000 karakterlik chunkâ€™lara (200 overlap) bÃ¶lÃ¼nÃ¼r. |
| **Embedding** | OpenAI Embeddings | Chunkâ€™lar `text-embedding-3-small` ile vektÃ¶rlenir. |
| **Vector store** | Astra DB | Chunkâ€™lar + embedding model ile Astraâ€™ya yazÄ±lÄ±r; ayrÄ±ca kullanÄ±cÄ± sorusu burada aranÄ±r (Search Query). |
| **KullanÄ±cÄ± giriÅŸi** | Chat Input, Text (Name) | Soru ve isim girilir; Name Message Historyâ€™de Session ID olarak kullanÄ±lÄ±r. |
| **GeÃ§miÅŸ** | Message History | Chat mesajlarÄ± saklanÄ±r; Ã§Ä±ktÄ± Promptâ€™taki `history` alanÄ±na gider. |
| **RAG birleÅŸtirme** | Parser â†’ Prompt Template | Astraâ€™dan gelen Search Results Parserâ€™da stringâ€™e Ã§evrilir â†’ `context`. `context` + `history` + `question` ile prompt oluÅŸturulur. |
| **Ãœretim** | OpenAI (gpt-4o-mini) | DÃ¼ÅŸÃ¼k temperature (~0.18â€“0.19) ile cevap Ã¼retilir. |
| **Ã‡Ä±ktÄ±** | Chat Output | Model Response kullanÄ±cÄ±ya â€œAIâ€ adÄ±yla gÃ¶sterilir. |

**RAGâ€™Ä±n anlamÄ±:** KullanÄ±cÄ± soru sorduÄŸunda Ã¶nce PDFâ€™ten ilgili kÄ±sÄ±mlar vector search ile bulunur, sonra bu baÄŸlam LLMâ€™e verilir; bÃ¶ylece cevap dokÃ¼mana dayalÄ± ve daha isabetli olur.

---

## Kurulum

1. **Python 3.10+** yÃ¼klÃ¼ olsun.
2. Langflowâ€™u kurun ve Ã§alÄ±ÅŸtÄ±rÄ±n:
   ```bash
   pip install langflow --pre --force-reinstall
   langflow run
   ```
3. TarayÄ±cÄ±da aÃ§Ä±lan arayÃ¼zden **New Project** â†’ **Blank Flow** ile yeni akÄ±ÅŸ oluÅŸturun (veya bu repodaki JSON flowâ€™u import edin).
4. **OpenAI API Key** ve **Astra DB** (Token, Endpoint, Collection) bilgilerini Langflowâ€™daki deÄŸiÅŸkenlere/credential alanlarÄ±na girin.
5. **Read File** nodeâ€™unda kullanacaÄŸÄ±nÄ±z PDFâ€™i (Ã¶rn. `Resturaunt Q&A.pdf`) seÃ§in veya proje klasÃ¶rÃ¼ne koyup yolunu verin.

---

## KullanÄ±m

1. Langflowâ€™da **Run** ile akÄ±ÅŸÄ± baÅŸlatÄ±n.
2. **Name** alanÄ±na kullanÄ±cÄ± adÄ± yazÄ±n.
3. **Chat Input** alanÄ±na sorunuzu yazÄ±n (Ã¶rn. â€œTell me about the hours of the storeâ€, â€œCan you tell me about the specials and the menu?â€).
4. Cevap, PDF baÄŸlamÄ± ve konuÅŸma geÃ§miÅŸi kullanÄ±larak saÄŸ taraftaki Chat Outputâ€™ta gÃ¶rÃ¼nÃ¼r.

---

## GitHub NotlarÄ±

- **Flow JSON**: Langflowâ€™dan **Export** ile akÄ±ÅŸÄ± JSON olarak indirip repoya ekleyin (Ã¶rn. `rag_flow.json`). BaÅŸkalarÄ± **Import** ile aynÄ± akÄ±ÅŸÄ± kurabilir.
- **PDF**: `Resturaunt Q&A.pdf` (veya kullandÄ±ÄŸÄ±nÄ±z PDF) repoya eklenebilir; `.gitignore` ile bÃ¼yÃ¼k dosyalarÄ± hariÃ§ tutabilirsiniz.
- **Gizli bilgiler**: API key ve Astra tokenâ€™larÄ± repoya eklemeyin. Langflowâ€™da credential/variable kullanÄ±n; OpenAI API Key ve Astra bilgilerini kullanÄ±cÄ±lar kendi ortamlarÄ±nda girer.
- **Collection adÄ±**: Astra tarafÄ±nda kullandÄ±ÄŸÄ±nÄ±z collection adÄ±yla Langflowâ€™daki ayarÄ±n tutarlÄ± olmasÄ±na dikkat edin.

---

## Kaynaklar

- [Langflow Docs / Install](https://docs.langflow.org/) Â· [Langflow GitHub](https://github.com/langflow-ai/langflow)  
- [Astra DB](https://dtsx.io/3vZk6n2)
#   R A G - Q A  
 